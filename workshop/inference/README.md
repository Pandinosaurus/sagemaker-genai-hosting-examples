# This is official repository for SageMaker AI hosting workshop

1. Lab 1: deploy multiple models using SageMaker DLC container & NVIDIA Triton container [lab 1](./lab1)
2. Lab 2: deploy state of the art LLM (Llama 3/DeepSeek/Qwen) [lab 2](./lab2)
3. Lab 3: deploy multiple state-of-the-art LLMs on a single endpoint with Scale-to-Zero [lab 3](./lab3)
4. Lab 4: deploy state-of-the-art ASR and CV models on a single endpoint [lab 4](./lab4)
5. Lab 5: use SageMaker Efficient Multi-Adapter Serving to deploy multiple LoRA adapters [lab 5](./lab5)
