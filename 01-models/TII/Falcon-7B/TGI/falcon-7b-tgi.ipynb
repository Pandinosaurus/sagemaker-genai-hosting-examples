{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eba763b2-d0f2-4e99-b375-8b4873116bcf",
   "metadata": {},
   "source": [
    "# Deploy Falcon 7B on Amazon SageMaker using Hugging Face Text Generation Inference (TGI) container\n",
    "\n",
    "## Resources\n",
    "- [Falcon-7B model card](https://huggingface.co/tiiuae/falcon-7b)\n",
    "- [TGI documentation](https://huggingface.co/docs/text-generation-inference/en/index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944fbc1a-b23a-43c5-af27-76fb7fdaa25f",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd04a8-6181-441e-b557-ee996281e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4702f11-0670-4d8b-9c62-f325d77be6f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "print(f\"sagemaker version: {sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76e135-46bb-4d47-a546-5de73abb5ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "region = sess._region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a74f0e5-966c-4620-8bb9-a33e84c9ceeb",
   "metadata": {},
   "source": [
    "## Step 2: Endpoint Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8b2c21-5edc-445d-938f-634e704c3173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "latest_version = \"1.4.0\" \n",
    "llm_image = get_huggingface_llm_image_uri(\"huggingface\", version=latest_version)\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f4cab6-c228-4fa3-a7d0-67feadcff891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.2xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 600\n",
    "\n",
    "# TGI config\n",
    "config = {\n",
    "    'HF_MODEL_ID': \"tiiuae/falcon-7b\", # model_id from hf.co/models\n",
    "    'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "    'MAX_INPUT_LENGTH': json.dumps(1024),  # Max length of input text\n",
    "    'MAX_TOTAL_TOKENS': json.dumps(2048),  # Max length of the generation (including input text)\n",
    "}\n",
    "\n",
    "# create HuggingFaceModel\n",
    "llm_model = HuggingFaceModel(\n",
    "    role = role,\n",
    "    image_uri = llm_image,\n",
    "    env = config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9c1edd-768a-4fa5-abad-91807651512e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deploy model to an endpoint\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\n",
    "llm = llm_model.deploy(\n",
    "    initial_instance_count = 1,\n",
    "    instance_type = instance_type,\n",
    "    container_startup_health_check_timeout = health_check_timeout, # timeout for loading the model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe50cfa-65fa-4fa3-b05b-0c1465a9ca09",
   "metadata": {},
   "source": [
    "## Step 3: Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64184c88-ad55-461b-9509-752eaee1a2f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define payload\n",
    "prompt = \"\"\"You are an helpful Assistant, called Falcon. Knowing everyting about AWS.\n",
    "\n",
    "User: Can you tell me something about Amazon SageMaker?\n",
    "Falcon:\"\"\"\n",
    "\n",
    "# hyperparameters for llm (remove \"\\nUser:\" from stop conditions)\n",
    "payload = {\n",
    "  \"inputs\": prompt,\n",
    "  \"parameters\": {\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.8,\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"repetition_penalty\": 1.03,\n",
    "    \"stop\": [\"<|endoftext|>\",\"</s>\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "# send request to endpoint\n",
    "response = llm.predict(payload)\n",
    "\n",
    "# print assistant respond\n",
    "assistant = response[0][\"generated_text\"][len(prompt):]\n",
    "print(assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4255ad-e07d-451a-945c-4b79889e8189",
   "metadata": {},
   "source": [
    "## Step 4: Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04cd1d9-d71f-409f-b6a4-d9a9624d6432",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm.delete_model()\n",
    "llm.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daaa34f-b756-42f0-b64b-24c17a68696c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
