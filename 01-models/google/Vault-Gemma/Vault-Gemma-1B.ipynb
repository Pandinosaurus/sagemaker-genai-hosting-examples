{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d68fb3-00f2-447c-b5e0-28fa18562392",
   "metadata": {},
   "source": [
    "# How to deploy the VaultGemma 1B for inference using Amazon SageMakerAI\n",
    "**Recommended kernel(s):** This notebook can be run with any Amazon SageMaker Studio kernel.\n",
    "\n",
    "In this notebook, you will learn how to deploy the Vault Gemma 1B model (HuggingFace model ID: [google/vaultgemma-1b](https://huggingface.co/google/vaultgemma-1b)) using Amazon SageMaker AI. \n",
    "\n",
    "VaultGemma is a variant of the Gemma family of lightweight, state-of-the-art open models from Google. It is pre-trained from the ground up using Differential Privacy (DP). This provides strong, mathematically-backed privacy guarantees for its training data, limiting the extent to which the model's outputs can reveal information about any single training example.\n",
    "\n",
    "VaultGemma uses a similar architecture as Gemma 2. VaultGemma is a pretrained model that can be instruction tuned for a variety of language understanding and generation tasks. Its relatively small size (< 1B parameters) makes it possible to deploy in environments with limited resources, democratizing access to state-of-the-art AI models that are built with privacy at their core.\n",
    "\n",
    "### License agreement\n",
    "* This model is gated on HuggingFace, please refer to the original [model card](https://huggingface.co/google/vaultgemma-1b) for license.\n",
    "* This notebook is a sample notebook and not intended for production use.\n",
    "\n",
    "### Execution environment setup\n",
    "This notebook requires the following third-party Python dependencies:\n",
    "* AWS [`sagemaker`](https://sagemaker.readthedocs.io/en/stable/index.html) with a version greater than or equal to 2.242.0\n",
    "\n",
    "Let's install or upgrade these dependencies using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fed1c92f-9fbc-47c9-b940-7dd07f962ef8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T19:04:31.124480Z",
     "iopub.status.busy": "2025-09-15T19:04:31.124212Z",
     "iopub.status.idle": "2025-09-15T19:04:37.189319Z",
     "shell.execute_reply": "2025-09-15T19:04:37.188352Z",
     "shell.execute_reply.started": "2025-09-15T19:04:31.124456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.4.0 requires nvidia-ml-py3<8.0,>=7.352.0, which is not installed.\n",
      "aiobotocore 2.21.1 requires botocore<1.37.2,>=1.37.0, but you have botocore 1.40.30 which is incompatible.\n",
      "autogluon-multimodal 1.4.0 requires transformers[sentencepiece]<4.50,>=4.38.0, but you have transformers 4.57.0.dev0 which is incompatible.\n",
      "autogluon-timeseries 1.4.0 requires transformers[sentencepiece]<4.50,>=4.38.0, but you have transformers 4.57.0.dev0 which is incompatible.\n",
      "sagemaker-studio-analytics-extension 0.2.0 requires sparkmagic==0.22.0, but you have sparkmagic 0.21.0 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc56cad7-ea97-43c4-835d-a56729549023",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c128cf97-3f1f-4176-87b4-1193cd9e9c0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T19:04:37.191175Z",
     "iopub.status.busy": "2025-09-15T19:04:37.190795Z",
     "iopub.status.idle": "2025-09-15T19:04:37.196080Z",
     "shell.execute_reply": "2025-09-15T19:04:37.195223Z",
     "shell.execute_reply.started": "2025-09-15T19:04:37.191132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.245.0\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import logging\n",
    "import time\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "print(sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bba6d4bf-5df9-4e3e-8a9e-a03897e0cb0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T19:04:37.197423Z",
     "iopub.status.busy": "2025-09-15T19:04:37.197103Z",
     "iopub.status.idle": "2025-09-15T19:04:38.010473Z",
     "shell.execute_reply": "2025-09-15T19:04:38.009714Z",
     "shell.execute_reply.started": "2025-09-15T19:04:37.197392Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "    sagemaker_session  = sagemaker.Session()\n",
    "    \n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e6b15cd-34e5-45f4-a68a-728aa9cc930d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T19:09:45.382881Z",
     "iopub.status.busy": "2025-09-15T19:09:45.382602Z",
     "iopub.status.idle": "2025-09-15T19:09:45.388802Z",
     "shell.execute_reply": "2025-09-15T19:09:45.387863Z",
     "shell.execute_reply.started": "2025-09-15T19:09:45.382860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vaultgemma-1b'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HF_MODEL_ID = \"google/vaultgemma-1b\"\n",
    "HUGGING_FACE_HUB_TOKEN = \"<REPLACE WITH TOKEN>\"\n",
    "\n",
    "base_name = HF_MODEL_ID.split('/')[-1].replace('.', '-').lower()\n",
    "model_lineage = HF_MODEL_ID.split('/')[0]\n",
    "base_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af864803-2921-4dda-95d7-6177b7d720ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T19:07:30.037543Z",
     "iopub.status.busy": "2025-09-15T19:07:30.037241Z",
     "iopub.status.idle": "2025-09-15T19:07:30.041271Z",
     "shell.execute_reply": "2025-09-15T19:07:30.040218Z",
     "shell.execute_reply.started": "2025-09-15T19:07:30.037519Z"
    }
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.m5.xlarge\"\n",
    "instance_count = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7245e684-aa6e-44ca-9451-10e0bee4b96e",
   "metadata": {},
   "source": [
    "## Create SageMaker Model\n",
    "\n",
    "#### HUGGING_FACE_HUB_TOKEN \n",
    "VaultGemma-1B is a gated model. Therefore, if you deploy model files hosted on the Hub, you need to provide your HuggingFace token as environment variable. This enables SageMaker AI to download the files at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e196ece-bada-486a-8f20-b78a381de41b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T19:13:36.536292Z",
     "iopub.status.busy": "2025-09-15T19:13:36.535990Z",
     "iopub.status.idle": "2025-09-15T19:13:36.714432Z",
     "shell.execute_reply": "2025-09-15T19:13:36.713736Z",
     "shell.execute_reply.started": "2025-09-15T19:13:36.536270Z"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'google/vaultgemma-1b',\n",
    "\t'HF_TASK':'text-generation',\n",
    "    'HF_TOKEN':HUGGING_FACE_HUB_TOKEN\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\ttransformers_version='4.49.0',\n",
    "\tpytorch_version='2.6.0',\n",
    "\tpy_version='py312',\n",
    "\tenv=hub,\n",
    "\trole=role, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40af4b17-30e9-4138-93f3-0589e4770815",
   "metadata": {},
   "source": [
    "## Deploy Model to SageMaker Endpoint\n",
    "\n",
    "Now we'll deploy our model to a SageMaker endpoint for real-time inference. This is a significant step that:\n",
    "1. Provisions the specified compute resources (M5 instance)\n",
    "2. Deploys the model container\n",
    "3. Sets up the endpoint for API access\n",
    "\n",
    "### Deployment Configuration\n",
    "- **Instance Count**: 1 instance for single-node deployment\n",
    "- **Instance Type**: `ml.m5.xlarge` for high-performance inference\n",
    "\n",
    "> ⚠️ **Important**: \n",
    "> - Deployment can take up to 15 minutes\n",
    "> - Monitor the CloudWatch logs for progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786fa8a9-d635-412f-adc5-4941a80b2b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=instance_count, # number of instances\n",
    "\tinstance_type=instance_type # ec2 instance type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc38898a-290b-482b-968c-f04b8674300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict({\n",
    "\t\"inputs\": \"Can you please let us know more details about your training using differential privacy?\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b85c32-d4df-45f1-84f4-86a296ad1c0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T19:14:57.135928Z",
     "iopub.status.busy": "2025-09-15T19:14:57.135661Z",
     "iopub.status.idle": "2025-09-15T19:14:57.139468Z",
     "shell.execute_reply": "2025-09-15T19:14:57.138566Z",
     "shell.execute_reply.started": "2025-09-15T19:14:57.135907Z"
    }
   },
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcef37c7-6b47-4c3b-b6b7-b266245b492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_model.delete_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
