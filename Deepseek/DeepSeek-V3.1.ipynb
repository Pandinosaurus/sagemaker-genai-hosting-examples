{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "993dcf59-dd85-4a31-a8cc-02c5d4be5dfe",
   "metadata": {},
   "source": [
    "# Deploy a DeepSeek-V3.1 on SageMaker AI endpoint using LMI container\n",
    "\n",
    "DeepSeek-V3.1 is a hybrid model that supports both thinking mode and non-thinking mode. Compared to the previous version, this upgrade brings improvements in multiple aspects:\n",
    "\n",
    "- **Hybrid thinking mode**: One model supports both thinking mode and non-thinking mode by changing the chat template.\n",
    "\n",
    "- **Smarter tool calling**: Through post-training optimization, the model's performance in tool usage and agent tasks has significantly improved.\n",
    "\n",
    "- **Higher thinking efficiency**: DeepSeek-V3.1-Think achieves comparable answer quality to DeepSeek-R1-0528, while responding more quickly.\n",
    "\n",
    "DeepSeek-V3.1 is post-trained on the top of DeepSeek-V3.1-Base, which is built upon the original V3 base checkpoint through a two-phase long context extension approach, following the methodology outlined in the original DeepSeek-V3 report. We have expanded our dataset by collecting additional long documents and substantially extending both training phases. The 32K extension phase has been increased 10-fold to 630B tokens, while the 128K extension phase has been extended by 3.3x to 209B tokens. Additionally, DeepSeek-V3.1 is trained using the UE8M0 FP8 scale data format to ensure compatibility with microscaling data formats.\n",
    "\n",
    "HuggingFace Repo: [deepseek-ai/DeepSeek-V3.1](https://huggingface.co/deepseek-ai/DeepSeek-V3.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f26a6-f3d6-463f-87c5-b91df1ac0559",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c01a4b2-b0d3-420c-8335-4efd984bb5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sagemaker --upgrade --quiet --no-warn-conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9183bf15-3f3f-4d70-91da-fe269ff421b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\")  # client to intreract with SageMaker\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")  # client to intreract with SageMaker Endpoints\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "print(f\"sagemaker version: {sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebdb7fb-319f-4db9-92ea-0c7a94212365",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "\n",
    "We are going to use SageMaker AI Large Model Inference (LMI) container, see [this](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#large-model-inference-containers) for more info.\n",
    "\n",
    "In this notebook, we are going to deploy the model directly from the HuggingFace hub. You can also can deploy the model from S3 (just point `HF_MODEL_ID` to S3 prefix where model weights are stored.\n",
    "\n",
    "Please note that your account should have a quota on `ml.p5en.48xlarge` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b45a5-0c97-470e-84e2-5bb1d01f089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTAINER_VERSION = \"0.33.0-lmi15.0.0-cu128\"\n",
    "inference_image = f\"763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:{CONTAINER_VERSION}\"\n",
    "instance_type = \"ml.p5en.48xlarge\"\n",
    "model_name = sagemaker.utils.name_from_base(\"model-ds\")\n",
    "endpoint_name = model_name\n",
    "timeout = 1800\n",
    "\n",
    "common_env = {\n",
    "    \"HF_MODEL_ID\": \"deepseek-ai/DeepSeek-V3.1\",\n",
    "}\n",
    "lmi_env = {\n",
    "    \"SERVING_FAIL_FAST\": \"true\",\n",
    "    \"OPTION_ASYNC_MODE\": \"true\",\n",
    "    \"OPTION_ROLLING_BATCH\": \"disable\",\n",
    "    \"OPTION_MAX_MODEL_LEN\": \"8192\",\n",
    "    \"OPTION_TENSOR_PARALLEL_DEGREE\": \"max\",\n",
    "    \"OPTION_ENTRYPOINT\": \"djl_python.lmi_vllm.vllm_async_service\",\n",
    "    \"OPTION_TRUST_REMOTE_CODE\": \"true\",\n",
    "}\n",
    "env = common_env | lmi_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7fb065-9a37-4949-88e4-d3162c8cd8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmi_model = sagemaker.Model(\n",
    "    image_uri=inference_image,\n",
    "    env=env,\n",
    "    role=role,\n",
    "    name=model_name,\n",
    ")\n",
    "\n",
    "lmi_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    container_startup_health_check_timeout=timeout,\n",
    "    endpoint_name=endpoint_name,\n",
    ")\n",
    "\n",
    "llm = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=sagemaker.serializers.JSONSerializer(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd48bdc-6d78-4f0f-8ee6-e5d0b55652cb",
   "metadata": {},
   "source": [
    "### Inference test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02998302-e93b-40c1-91aa-7d719343f7c9",
   "metadata": {},
   "source": [
    "#### Standard (non-thinking) request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72c6a984-289d-44f2-9a42-5ecbf35744ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T18:12:42.017821Z",
     "iopub.status.busy": "2025-08-24T18:12:42.017497Z",
     "iopub.status.idle": "2025-08-24T18:13:14.835622Z",
     "shell.execute_reply": "2025-08-24T18:13:14.835056Z",
     "shell.execute_reply.started": "2025-08-24T18:12:42.017800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############\n",
      "Of course! London is packed with iconic landmarks, world-class museums, and vibrant neighborhoods. Here is a list of popular places to visit, categorized to help you plan your trip.\n",
      "\n",
      "### **The Absolute Icons (The \"Must-Do\" List)**\n",
      "These are the landmarks that define London's skyline and history.\n",
      "\n",
      "1.  **The Houses of Parliament & Big Ben:** The stunning Gothic revival building that houses the UK government. The Elizabeth Tower (commonly known as Big Ben) is one of the most recognizable symbols in the world.\n",
      "2.  **Buckingham Palace:** The official London residence of the King. The **Changing of the Guard** ceremony is a major draw (check schedules online).\n",
      "3.  **The Tower of London:** A historic castle on the River Thames. Explore nearly 1,000 years of history, see the Crown Jewels, and be entertained by the Yeoman Warders (Beefeaters).\n",
      "4.  **Tower Bridge:** The famous bascule and suspension bridge next to the Tower of London. You can walk across for free or pay to go inside the towers and walk on the high-level glass walkways.\n",
      "5.  **St. Paul's Cathedral:** Sir Christopher Wren's masterpiece with its magnificent dome. You can climb to the top for breathtaking views of London.\n",
      "6.  **Westminster Abbey:** The historic church where coronations, royal weddings, and burials have taken place for centuries.\n",
      "\n",
      "### **World-Class Museums & Galleries (Most with Free Entry!)**\n",
      "London's major museums offer free entry to their permanent collections, though donations are appreciated.\n",
      "\n",
      "7.  **The British Museum:** Home to a vast collection of world art and artifacts, including the Rosetta Stone and the Parthenon Marbles.\n",
      "8.  **The National Gallery:** Located in Trafalgar Square, it houses a renowned collection of Western European paintings from the 13th to the 19th centuries (Van Gogh, da Vinci, Turner, etc.).\n",
      "9.  **The Natural History Museum:** Famous for its stunning cathedral-like architecture and incredible dinosaur exhibits, including a moving T-Rex model.\n",
      "10. **The Victoria and Albert Museum (V&A):** The world's leading museum of art, design, and performance, with everything from fashion and sculpture to ancient jewelry.\n",
      "11. **The Science Museum:** Great for all ages, with interactive galleries on space, technology, and medicine.\n",
      "\n",
      "### **Vibrant Neighborhoods & Areas**\n",
      "Experience the real London by exploring its diverse districts.\n",
      "\n",
      "12. **Covent Garden:** Known for its street performers, boutique shops, the Apple Market, and the Royal Opera House. Always buzzing with energy.\n",
      "13. **Soho & Chinatown:** The heart of London's entertainment district, packed with restaurants, pubs, theatres, and a vibrant LGBTQ+ scene. Chinatown's gate leads to fantastic East Asian cuisine.\n",
      "14. **South Bank:** A lively walk along the River Thames from the London Eye past the Southbank Centre, National Theatre, Shakespeare's Globe, and Tate Modern, with great street food and markets.\n",
      "15. **Notting Hill:** Famous for its pastel-colored houses, the antique stalls of Portobello Road Market (especially lively on Saturdays), and the annual Notting Hill Carnival.\n",
      "16. **Camden Town:** A hub of alternative culture, known for its sprawling markets selling everything from vintage clothes to unique crafts and its legendary music venues.\n",
      "\n",
      "### **Parks & Green Spaces**\n",
      "Escape the bustle in these beautiful royal parks.\n",
      "\n",
      "17. **Hyde Park:** One of London's largest parks, home to the Serpentine Lake, Speaker's Corner, and numerous events.\n",
      "18. **Regent's Park:** Contains London Zoo, beautiful rose gardens, and an open-air theatre. It's also where you can stroll to the top of **Primrose Hill** for one of the best panoramic views of the city skyline.\n",
      "19. **Greenwich Park:** Offers stunning views of Canary Wharf and the City from the top of the hill. Home to the Royal Observatory (stand on the Prime Meridian Line), the Cutty Sark clipper ship, and the National Maritime Museum.\n",
      "\n",
      "### **Modern Landmarks & Viewpoints**\n",
      "\n",
      "20. **The London Eye:** The giant observation wheel on the South Bank provides unparalleled 360-degree views of the city. Especially beautiful at sunset.\n",
      "21. **The Shard:** Western Europe's tallest building. You can visit the viewing gallery at the top (\"The View from The Shard\") or book a table at one of its bars or restaurants for a view with a drink.\n",
      "22. **Sky Garden:** London's highest public garden, located at the top of the \"Walkie Talkie\" building (20 Fenchurch Street). It offers fantastic free views, but you **must book tickets in advance** online.\n",
      "\n",
      "### **For a Unique Experience**\n",
      "\n",
      "*   **Leadenhall Market:** A beautiful covered Victorian market in the City of London, often used as a filming location for Diagon Alley in the Harry Potter films.\n",
      "*   **Neal's Yard:** A hidden, brightly coloured courtyard in Covent Garden, home to quirky cafes and health food stores.\n",
      "*   **Churchill War Rooms:** Explore the underground bunker from which Winston Churchill directed the WWII effort.\n",
      "\n",
      "This list just scratches the surface, but it covers the essential experiences for any first-time visitor. Enjoy your trip to London\n",
      "###############\n",
      "\n",
      "{'prompt_tokens': 12, 'total_tokens': 1119, 'completion_tokens': 1107, 'prompt_tokens_details': None}\n"
     ]
    }
   ],
   "source": [
    "payload={\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Name popular places to visit in London?\"}\n",
    "    ],\n",
    "}\n",
    "\n",
    "res = smr_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                 Body=json.dumps(payload),\n",
    "                                 ContentType=\"application/json\")\n",
    "\n",
    "response = json.loads(res[\"Body\"].read().decode(\"utf8\"))\n",
    "content = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "usage = response[\"usage\"] \n",
    "\n",
    "print(\"###############\\n\" + content + \"\\n###############\\n\")\n",
    "print(usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af06046b-e6f5-4acd-9e76-5ad4926ef5d3",
   "metadata": {},
   "source": [
    "#### Switching to \"thinking\" mode\n",
    "\n",
    "Note `</think>` token in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1a9e7c3-c965-43ae-947d-ca6ae9212201",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T18:14:29.535990Z",
     "iopub.status.busy": "2025-08-24T18:14:29.535668Z",
     "iopub.status.idle": "2025-08-24T18:14:43.175598Z",
     "shell.execute_reply": "2025-08-24T18:14:43.175082Z",
     "shell.execute_reply.started": "2025-08-24T18:14:29.535970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############\n",
      "First, the question is: \"What is bigger 9.11 or 9.8?\" I need to compare these two numbers.\n",
      "\n",
      "Both numbers are decimals. 9.11 and 9.8. I should think of them in terms of place value to compare them properly.\n",
      "\n",
      "The number 9.11 has digits: 9 (units), 1 (tenths), and 1 (hundredths). So, it's 9 + 0.1 + 0.01 = 9.11.\n",
      "\n",
      "The number 9.8 has digits: 9 (units) and 8 (tenths). So, it's 9 + 0.8 = 9.8.\n",
      "\n",
      "To compare them, I should look at the whole number part first. Both have the same whole number, which is 9. So, I need to compare the decimal parts.\n",
      "\n",
      "The decimal part of 9.11 is 0.11, and the decimal part of 9.8 is 0.8.\n",
      "\n",
      "Now, 0.8 is the same as 0.80, which is greater than 0.11 because 80 hundredths is greater than 11 hundredths.\n",
      "\n",
      "I can also think in terms of tenths: 9.8 has 8 tenths, while 9.11 has 1 tenth and 1 hundredth, so 8 tenths is greater than 1 tenth.\n",
      "\n",
      "Therefore, 9.8 is greater than 9.11.\n",
      "\n",
      "So, the bigger number is 9.8.\n",
      "\n",
      "I should make sure there's no trick here. Sometimes people might misread 9.11 as September 11, but in this context, it's clearly a decimal number because of the way it's written with a dot. The question says \"9.11\" and \"9.8\", so it's numerical.\n",
      "\n",
      "Thus, my answer should be that 9.8 is bigger.</think>9.8 is bigger than 9.11. \n",
      "\n",
      "This is because both numbers have the same whole number part (9), but when comparing the decimal parts, 0.8 (which is equivalent to 0.80) is greater than 0.11.\n",
      "###############\n",
      "\n",
      "{'prompt_tokens': 17, 'total_tokens': 475, 'completion_tokens': 458, 'prompt_tokens_details': None}\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is bigger 9.11 or 9.8?\"}\n",
    "    ],\n",
    "    \"chat_template_kwargs\": {\n",
    "        \"thinking\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "res = smr_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                 Body=json.dumps(payload),\n",
    "                                 ContentType=\"application/json\")\n",
    "\n",
    "response = json.loads(res[\"Body\"].read().decode(\"utf8\"))\n",
    "content = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "usage = response[\"usage\"] \n",
    "\n",
    "print(\"###############\\n\" + content + \"\\n###############\\n\")\n",
    "print(usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266372a3-5a93-4e47-b6cd-2a897e2ff918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T18:11:01.326877Z",
     "iopub.status.busy": "2025-08-24T18:11:01.326544Z",
     "iopub.status.idle": "2025-08-24T18:11:01.329622Z",
     "shell.execute_reply": "2025-08-24T18:11:01.329118Z",
     "shell.execute_reply.started": "2025-08-24T18:11:01.326856Z"
    }
   },
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "657e0405-fd55-40cc-b3fc-8cdb2949f377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T18:14:52.888464Z",
     "iopub.status.busy": "2025-08-24T18:14:52.887953Z",
     "iopub.status.idle": "2025-08-24T18:14:52.896211Z",
     "shell.execute_reply": "2025-08-24T18:14:52.895696Z",
     "shell.execute_reply.started": "2025-08-24T18:14:52.888443Z"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class LineIterator:\n",
    "    def __init__(self, stream):\n",
    "        self.byte_iterator = iter(stream)\n",
    "        self.buffer = io.BytesIO()\n",
    "        self.read_pos = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        while True:\n",
    "            self.buffer.seek(self.read_pos)\n",
    "            line = self.buffer.readline()\n",
    "            if line and line[-1] == ord(\"\\n\"):\n",
    "                self.read_pos += len(line)\n",
    "                return line[:-1]\n",
    "            try:\n",
    "                chunk = next(self.byte_iterator)\n",
    "            except StopIteration:\n",
    "                if self.read_pos < self.buffer.getbuffer().nbytes:\n",
    "                    continue\n",
    "                raise\n",
    "            if \"PayloadPart\" not in chunk:\n",
    "                print(\"Unknown event type:\" + chunk)\n",
    "                continue\n",
    "            self.buffer.seek(0, io.SEEK_END)\n",
    "            self.buffer.write(chunk[\"PayloadPart\"][\"Bytes\"])\n",
    "\n",
    "def stream_response(endpoint_name, inputs, thinking=False):    \n",
    "    body = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": inputs}\n",
    "        ],\n",
    "        \"chat_template_kwargs\": {\n",
    "            \"thinking\": thinking\n",
    "        },\n",
    "        \"stream\": True\n",
    "    }\n",
    "\n",
    "    resp = smr_client.invoke_endpoint_with_response_stream(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=json.dumps(body),\n",
    "        ContentType=\"application/json\",\n",
    "    )\n",
    "\n",
    "    event_stream = resp[\"Body\"]\n",
    "    start_json = b\"{\"\n",
    "    full_response = \"\"\n",
    "    start_time = time.time()\n",
    "    token_count = 0\n",
    "\n",
    "    for line in LineIterator(event_stream):\n",
    "        if line != b\"\" and start_json in line:\n",
    "            data = json.loads(line[line.find(start_json):].decode(\"utf-8\"))\n",
    "            token_text = data['choices'][0]['delta'].get('content', '')\n",
    "            full_response += token_text\n",
    "            token_count += 1\n",
    "\n",
    "            # Calculate tokens per second\n",
    "            elapsed_time = time.time() - start_time\n",
    "            tps = token_count / elapsed_time if elapsed_time > 0 else 0\n",
    "\n",
    "            # Clear the output and reprint everything\n",
    "            clear_output(wait=True)\n",
    "            print(full_response)\n",
    "            print(f\"\\nTokens per Second: {tps:.2f}\", end=\"\")\n",
    "\n",
    "    print(\"\\n\") # Add a newline after response is complete\n",
    "    \n",
    "    return full_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be81fb01-375b-49fc-83be-0ad1142a3956",
   "metadata": {},
   "source": [
    "#### Streaming invocation in \"thinking\" mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fcfee06-4a1a-40f7-94e5-07032a19b6dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T18:15:03.461561Z",
     "iopub.status.busy": "2025-08-24T18:15:03.461226Z",
     "iopub.status.idle": "2025-08-24T18:15:12.380835Z",
     "shell.execute_reply": "2025-08-24T18:15:12.380372Z",
     "shell.execute_reply.started": "2025-08-24T18:15:03.461541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First, the question is: \"How many 'r' in word 'strawberries'?\" I need to count the number of times the letter 'r' appears in the word \"strawberries\".\n",
      "\n",
      "Let me write down the word: s-t-r-a-w-b-e-r-r-i-e-s.\n",
      "\n",
      "Now, I'll go through each letter and count the 'r's.\n",
      "\n",
      "Starting from the beginning:\n",
      "\n",
      "- s: not r\n",
      "\n",
      "- t: not r\n",
      "\n",
      "- r: yes, that's one r\n",
      "\n",
      "- a: not r\n",
      "\n",
      "- w: not r\n",
      "\n",
      "- b: not r\n",
      "\n",
      "- e: not r\n",
      "\n",
      "- r: yes, that's the second r\n",
      "\n",
      "- r: yes, that's the third r\n",
      "\n",
      "- i: not r\n",
      "\n",
      "- e: not r\n",
      "\n",
      "- s: not r\n",
      "\n",
      "So, I have three 'r's in \"strawberries\".\n",
      "\n",
      "I should double-check to make sure I didn't miss any. The word has 12 letters, and the 'r's are at positions 3, 8, and 9. Yes, that seems correct.\n",
      "\n",
      "Therefore, the answer should be 3.</think>The word \"strawberries\" contains **3** instances of the letter 'r'. Here's a breakdown for clarity:\n",
      "\n",
      "- The word is: s-t-r-a-w-b-e-r-r-i-e-s\n",
      "- The 'r's appear at positions 3, 8, and 9.\n",
      "\n",
      "Tokens per Second: 33.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = \"How many 'r' in word 'strawberries'\"\n",
    "output = stream_response(endpoint_name, inputs, thinking=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece46aca-c35f-44c9-9887-90982cd30c8b",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "654b369f-8f8d-4039-baed-9f2206fdd32b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T18:16:00.144578Z",
     "iopub.status.busy": "2025-08-24T18:16:00.144236Z",
     "iopub.status.idle": "2025-08-24T18:16:00.533080Z",
     "shell.execute_reply": "2025-08-24T18:16:00.532478Z",
     "shell.execute_reply.started": "2025-08-24T18:16:00.144557Z"
    }
   },
   "outputs": [],
   "source": [
    "sess.delete_endpoint(endpoint_name)\n",
    "sess.delete_endpoint_config(endpoint_name)\n",
    "sess.delete_model(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
